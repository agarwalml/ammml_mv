# ammml_mv

## Context

This project is part of 11-877 Advanced Topics in Multimodal Machine Learning at Carnegie Mellon University by Santiago Benoit and Mehul Agarwal under the guidance of Professor Louis-Philippe Morency.

## Description

We use deep multimodal learning techniques to create music videos that are perfectly synced with a given piece of music and its lyrics. This project is designed to take advantage of the power of natural language processing (NLP) and computer vision to generate a context-specific visual experience that complements the audio.

# Additional Required Repos

Place these in this directory.

giffusion: https://github.com/DN6/giffusion.git
MultimodalMusicEmotion: https://github.com/santient/MultimodalMusicEmotion.git

